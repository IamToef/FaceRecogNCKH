{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamToef/FaceRecogNCKH/blob/main/FaceRegconizing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n8tEeNqPDGP",
        "outputId": "c692b3b3-903b-42b0-da21-ea9ff79a7718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: insightface in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from insightface) (1.26.4)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from insightface) (1.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from insightface) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from insightface) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from insightface) (3.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from insightface) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from insightface) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from insightface) (1.3.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from insightface) (0.23.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from insightface) (3.0.10)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from insightface) (1.4.12)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from insightface) (3.10.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (4.12.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (2.8.2)\n",
            "Requirement already satisfied: albucore>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (0.0.12)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (4.10.0.84)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2024.7.24)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (2.8.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->insightface) (3.20.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface) (3.5.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from albucore>=0.0.11->albumentations->insightface) (2.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.16.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.18.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFFv7o9KMa4Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch .nn as nn\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Subset , DataLoader, Dataset\n",
        "from torchvision.datasets import LFWPeople\n",
        "from torchvision.models import resnet34\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from insightface.model_zoo import get_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lfw_dataset = LFWPeople(root='./data', split='train',  download=True)\n",
        "lfw_dataset"
      ],
      "metadata": {
        "id": "Jfal7CTYMgmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85aa17f2-bb89-4754-91a9-e664ba2bca0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset LFWPeople\n",
              "    Number of datapoints: 9525\n",
              "    Root location: ./data/lfw-py\n",
              "    Alignment: funneled\n",
              "    Split: train\n",
              "    Classes (identities): 5749"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = len(lfw_dataset)\n",
        "indices = list(range(num_samples))\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "9CWj4OdpM4bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset = Subset(lfw_dataset, train_idx)\n",
        "test_subset = Subset(lfw_dataset, test_idx)\n",
        "\n",
        "print(f'Training set size: {len(train_subset)}')\n",
        "print(f'Test set size: {len(test_subset)}')"
      ],
      "metadata": {
        "id": "p0RRxNSXNJSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010915a6-9f18-492f-ed55-75926e74329b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 7620\n",
            "Test set size: 1905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(a) Xây dựng hàm tiền xử lý dữ liệu hình ảnh**"
      ],
      "metadata": {
        "id": "4GV-Q8K7RIp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 64\n",
        "img_transforms = transforms.Compose ([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.5, 0.5, 0.5],\n",
        "        [0.5, 0.5, 0.5]\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "8jePxkhENgvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ":**(b) Xây dựng class LFWDataset**"
      ],
      "metadata": {
        "id": "J5W-_WooQ_ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LFWDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        original_idx = self.data.indices[idx]\n",
        "        image, label = self.data.dataset[original_idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "a12DmEo7NuBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(c) Khai báo dataloader**"
      ],
      "metadata": {
        "id": "Gc_yL1egQvfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_BATCH_SIZE = 512\n",
        "VAL_BATCH_SIZE = 256\n",
        "\n",
        "train_dataset = LFWDataset(data=train_subset, transform=img_transforms)\n",
        "test_dataset = LFWDataset(data=test_subset, transform=img_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "rIpXQDkhOaUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Xây dựng mô hình**"
      ],
      "metadata": {
        "id": "7t4R93QjQ2dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LFWModel(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(LFWModel, self).__init__()\n",
        "        resnet = resnet34(pretrained=True)\n",
        "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        in_features = resnet.fc.in_features\n",
        "        self.fc = nn.Linear(in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Uh4QEyHORQ4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "N_CLASSES = 5749\n",
        "model = LFWModel(N_CLASSES).to(device)\n",
        "test_input = torch.rand(1, 3, 224, 224).to(device)\n",
        "with torch.no_grad():\n",
        "  output = model(test_input)\n",
        "  print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAjiQvrBiZWo",
        "outputId": "638fb77f-fc7b-42f1-df48-2ad23bc03e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5749])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = 10\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY= 1e-5\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR, weight_decay = WEIGHT_DECAY)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "  train_losses = []\n",
        "  model.train()\n",
        "  for images, labels in train_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "  train_loss = sum(train_losses)/len(train_losses)\n",
        "\n",
        "  val_losses = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      val_losses.append(loss.item())\n",
        "\n",
        "  val_loss = sum(val_losses)/len(val_losses)\n",
        "\n",
        "  print(f'EPOCH {epoch + 1}:\\tTrain loss: {train_loss: .3f}\\tVal loss: {val_loss: .3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI7Hg8FAi5F7",
        "outputId": "8fe8d061-7823-4fc7-97f9-9de62cab11f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\tTrain loss:  8.742\tVal loss:  8.420\n",
            "EPOCH 2:\tTrain loss:  6.436\tVal loss:  8.646\n",
            "EPOCH 3:\tTrain loss:  4.804\tVal loss:  8.571\n",
            "EPOCH 4:\tTrain loss:  3.469\tVal loss:  8.591\n",
            "EPOCH 5:\tTrain loss:  2.543\tVal loss:  8.645\n",
            "EPOCH 6:\tTrain loss:  1.967\tVal loss:  8.824\n",
            "EPOCH 7:\tTrain loss:  1.610\tVal loss:  9.000\n",
            "EPOCH 8:\tTrain loss:  1.362\tVal loss:  9.175\n",
            "EPOCH 9:\tTrain loss:  1.181\tVal loss:  9.304\n",
            "EPOCH 10:\tTrain loss:  1.045\tVal loss:  9.429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = 'FR_weights.pt'\n",
        "torch.save(model.state_dict(), SAVE_PATH)"
      ],
      "metadata": {
        "id": "uJOjoddNzyIg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}